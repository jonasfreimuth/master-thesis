# Methods & Data

```{r load-data, include = FALSE}
import::from("here", "here")
import::from("magrittr", .all = TRUE)
import::from("purrr", "pluck", "map_vec")

import::from(
  "utils.R",
  "load_param_table_dir",
  "formatted_yaml_value",
  .character_only = TRUE,
  .directory = here("modules")
)

suppressMessages(here::i_am("bookdown/02-methods.Rmd"))

source(here("modules/utils.R"))

param_table_dir <- here("cancer-cleaning-output/param_tables")
param_tables <- load_param_table_dir(param_table_dir)

# Define short functions for inserting text, so as not to break flow too much.

txt_rs_stc <- function(name) {
  # Use global param_tables.
  formatted_yaml_value(
    param_obj = param_tables$yaml_objs$rnd_sim$static_parameters,
    value_name = name
  )
}

txt_ss_stc <- function(name) {
  # Use global param_tables.
  formatted_yaml_value(
    param_obj = param_tables$yaml_objs$scrna_sim$static_parameters,
    value_name = name
  )
}

txt_ss_pb <- function(name) {
  # Use global param_tables.
  formatted_yaml_value(
    param_obj = param_tables$yaml_objs$scrna_sim$pbulk_stats,
    value_name = name
  )
}

txt_pr_stc <- function(name) {
  # Use global param_tables.
  formatted_yaml_value(
    param_obj = param_tables$yaml_objs$pred$static_parameters %>%
      # There are sub-lists to this param_obj, but we don't want those.
      extract(!map_vec(., is.list)),
    value_name = name
  )
}

txt_pr_cat <- function(name) {
  # Use global param_tables.
  formatted_yaml_value(
    param_obj = param_tables$yaml_objs$pred$static_parameters$categorical,
    value_name = name
  )
}

txt_pr_cat_stat <- function(name) {
  # Use global param_tables.
  formatted_yaml_value(
    param_obj = param_tables$yaml_objs$pred$categorical_stat,
    value_name = name
  )
}

txt_pr_srv <- function(name) {
  # Use global param_tables.
  formatted_yaml_value(
    param_obj = param_tables$yaml_objs$pred$static_parameters$survival,
    value_name = name
  )
}

txt_pr_srv_stat <- function(name) {
  # Use global param_tables.
  formatted_yaml_value(
    param_obj = param_tables$yaml_objs$pred$survival_stat,
    value_name = name
  )
}

txt_pr_evl <- function(name) {
  # Use global param_tables.
  formatted_yaml_value(
    param_obj = param_tables$yaml_objs$pred$static_parameters$evaluation,
    value_name = name
  )
}
```


## Transcriptome cleaning overview

Following from the basic deconvolution model of equation
\@ref(eq:basic-matrix-deconv), the problem becomes tractable when the signature
matrix $\mathbf{S}$ is already known as it is then reduced to a system of linear
equations for each bulk $k$:

\begin{equation*}
  \mathbf{B}_{\cdot k} = \mathbf{S} \mathbf{C}_{\cdot k}
  \qquad \forall 1 \leq k \leq n
\end{equation*}

To reduce the solution space, usually a non-negativity constraint is placed on
elements of $\mathbf{C}$, as a bulk can't contain negative concentrations
[@venet.2001]. Adding this constraint, and considering the bulks $\mathbf{b}$
and associated concentration vectors $\mathbf{c}$ independently the problem can
be formulated as

\begin{equation*}
  \mathbf{b} = \mathbf{S} \mathbf{c}
  \qquad s.t.\ \mathbf{c}_i < 0 \; \forall 1 \leq j \leq m
\end{equation*}

This can then be solved using a least-squares method with the objective function

\begin{equation}
  \min_{\mathbf{c} \geq 0} \|\mathbf{Sc} - \mathbf{b}\|^2
\end{equation}

Under the assumption that cancer cells vary stronger in their expression than
the other cells in the microenvironment, we can expect the residuals to contain
much of this excess variation. Using these residuals as a measure of true cancer
expression thus represents a way to “clean” the bulk cancer expression of the
expression of non-cancer cells. It may be possible to further enhance the signal
of pure expression of cancer cells by simply not including the reference profile
for cancer cells during deconvolution. While this would certainly lead to less
accurate results for the prediction of cell type abundance as some proportion of
cancer cell gene expression would be erroneously attributed to other cell types
[although this issue seems to be already present in the ideal case, see
@aran.2017], the residuals might then more accurately reflect the patterns of
cancer cell type expression as when they are already accounted for by the
inclusion of the cancer cell type reference profile.

Prior information on the expression profiles of the cell types present in a set
of bulk RNA-seq samples may be obtained in different ways. Relatively simple
approaches like expression profiling of cultured purified cell lines allow for
characterization of cell type specific expression profiles at low cost and
effort, but require normalization to eliminate bias from differing cell counts.
More complex methods allowing for single cell level expression quantification
like micro-dissection, fluorescence-activated cell sorting, and more recently
scRNA-seq do not have this problem, but are limited in application due to their
cost. Single cell based reference profiles have a further advantage in
least-squares deconvolution since they allow quantification of actual cell type
counts rather than proportions only, since the profile corresponds to the
expression of a single cell. For this reason, along with the need to construct
pseudo bulks for which single-cell data is needed, I generally use scRNA derived
references here (except for random simulations). To construct reference profiles
from scRNA-seq data, I simply averaged all cells annotated as belonging to the
same cell type. I also restricted the set of genes used for deconvolution to the
most discriminant ones (see the later
[pseudobulk section](#scrna-seq-pseudo-bulks)), to increase deconvolution
accuracy and reduce computation time.

<!-- Talk about previous work on marker genes for deconvolution? -->

After reference creation, the computation of residuals as a measure for true
expression of cancerous cells is relatively straightforward. First the
untransformed bulk RNA-seq data is deconvoluted using the also untransformed
reference profiles. Using untransformed data has been shown to yield more
accurate results for least-squares based deconvolution of microarray data
[@zhong.2011], which I saw to hold true for the data I use here in preliminary
experiments. Throughout this work, I always used the `nnls` package
[@katharinem.mullen.2023] in the `R` programming language [@rcoreteam.2023] for
this step. The deconvolution model estimates for cell type counts ($\mathbf{c}$)
are then used to compute the *full* predicted gene expression vector of the
deconvolution model $\mathbf{\hat{b}}$ using all genes from the reference
profile, not only the marker genes used in deconvolution. From this the
residuals $\mathbf{\epsilon}$ can then be computed:

\begin{equation*}
  \mathbf{\epsilon} = \mathbf{b} - \mathbf{\hat{b}}
\end{equation*}

<!-- FIXME Add a diagram explaining the relationship between fitted values,
residuals, and cancer expression estimation. -->

From this it also follows that the estimated TME expression in this context is
simply $\mathbf{\hat{b}}$. For real-world applications (i.e. everything except
[normally distributed simulation](#normally-distributed-simulation)), both
$\mathbf{b}$ and $\mathbf{\hat{b}}$ are log-transformed (adding a pseudo-count
of one to preserve values of zero on the original scale;
$\mathbf{x}_{\text{trans}} = \log_{10}{\left( \mathbf{x} + 1 \right)}$) so that
the variance of the residuals stays reasonably consistent across the spectrum of
actual and predicted gene expression values. Another consideration are erroneous
zero abundance estimates, as in that case the signal of cancer expression (which
is supposed to come from the *difference* of fitted and observed bulk expression
values) is overshadowed by noise from genes strongly expressed in the cell types
estimated at zero. High gene expression estimates for cancer due to zero
estimates from other cell types might, however, also be a genuine signal. To
mitigate this, I removed all genes which were estimated at an expression of zero
in the fitted values of the deconvolution model, representing a trade-off
between preserving the actual cancer expression signal in low fitted-values
compared to the noise added by erroneous zero estimates for cell type
expression.

## Proof of concept

Before applying my method to real-world problems, I carried out two analyses
assessing its performance under ideal conditions. First, I explored the method's
behavior when applied to normally distributed data with varying levels of noise
added, and then quantified its performance on more realistic data using
scRNA-seq derived pseudo-bulk data.

### Normally distributed simulation

To demonstrate the principle of the method, I first generated model expression
profiles, simulated measurements of expression quantification, and analyzed the
behavior of my method on it. The simulated expression profiles
$\mathbf{S}_{sim}$ were generated by sampling expression data for $n =
`r txt_rs_stc("n_transcript")`$ transcripts & $m = `r txt_rs_stc("n_celltype")`$
cell types from a normal distribution:

\begin{equation*}
  \mathbf{S}_{sim} \sim \mathcal{N}(0, \sigma_{gene}^2)
\end{equation*}

For each set of expression profiles, I then simulated the result of a bulk
RNA-seq experiment $\mathbf{b}_{sim}$ by convoluting randomly sampled cell type
counts with their respective reference profiles. For this, I first sampled cell
type counts $\mathbf{c}_{sim}$ for all cell types uniformly at random:

\begin{equation*}
  \mathbf{c}_{sim} \sim \mathcal{U}(0, 1)
\end{equation*}

As I wanted to simulate biological variability, I could not carry out the
convolution by simple matrix multiplication of $\mathbf{S}_{sim}$ and
$\mathbf{c}_{sim}$, but needed to simulate individual cells. I did this by
assembling a matrix of individual cell expression $\mathbf{P}$ through repeating
cell type reference profiles as often as their simulated count:

\begin{equation*}
    \mathbf{P} = \left( \begin{array}{c|c|c|c}
        \left(
          \mathbf{S}_{\text{sim}}
        \right)_{\cdot 1} \otimes \mathbf{1}_{1 \times \mathbf{c}_1} &
        \left(
          \mathbf{S}_{\text{sim}}
        \right)_{\cdot 2} \otimes \mathbf{1}_{1 \times \mathbf{c}_2} &
        \cdots &
        \left(
          \mathbf{S}_{\text{sim}}
        \right)_{\cdot m} \otimes \mathbf{1}_{1 \times \mathbf{c}_m}
    \end{array} \right)
\end{equation*}

Then, to simulate the deviation of individual cells from their reference
profile, I added a matrix of normally distributed noise
$\mathbf{N}_{\text{cancer homo.}}$.

\begin{equation*}
  \mathbf{N}_{\text{cancer homo.}} \sim \mathcal{N}(0, \sigma_{cellvar}^2)
\end{equation*}

I also optionally simulated cancer cells having more heterogeneous expression
($\mathbf{N}_{\text{cancer het.}}$) by using a greater standard deviation for
simulating their profile deviation, for this I multiplied it by a factor of $x =
`r txt_rs_stc("cancer_noise_rel")`$.

\begin{equation*}
  \begin{aligned}
    \mathbf{N}_{\text{non cancer}} &\sim \mathcal{N}(0, \sigma_{cellvar}^2) \\
    \mathbf{N}_{\text{cancer}} &\sim \mathcal{N}(
      0, \left( \sigma_{cellvar} * x \right)^2
    )
  \end{aligned} \\
  \mathbf{N}_{\text{cancer het.}} = \left( \begin{array}{c|c}
    \mathbf{N}_{\text{non cancer}} & \mathbf{N}_{\text{cancer}}
  \end{array} \right)
\end{equation*}

The final matrices of simulated cell expression $\mathbf{Q}$, using both
versions of $\mathbf{N}$ were then simply:

\begin{equation*}
  \begin{aligned}
    \mathbf{Q}  &= \mathbf{P} + \mathbf{N}
  \end{aligned}
\end{equation*}

To obtain the bulk vector for the mixture $b_{\text{sim}}$, I just summed up the
expression of each transcript $i$ across the $m$ cells and simulated technical
noise $\mathbf{e}$ from the sequencing process as normally distributed additive
noise:

\begin{equation*}
  \mathbf{e} \sim \mathcal{N}(0, \sigma_{\text{tech}}^2)
\end{equation*}

\begin{equation*}
  \left( b_{\text{sim}} \right)_{i} = \sum_{j = 1}^{m} \left(
    q_{i,j} + e_j
  \right)
  \quad \forall \ 1 \leq i \leq n
\end{equation*}

I varied $\sigma_{\text{tech}}$ across a range of values to understand my
method's behavior under conditions of both relatively high and low technical
noise (see table XXX). Finally, I deconvoluted the resulting set of simulated
bulks with the varying amounts of technical noise and optionally heterogeneous
cancer expression again with associated reference expression profiles, each
either including or excluding the designated cancer cell type. I analyzed the
effect of these parameters on the estimation accuracy of cell type counts via
the inverse root mean squared error ($1 / RMSE$) between true and predicted cell
type counts. Lastly, I examined the relationship between the distribution of
residuals to the true expression profile of the cancerous cell type using
Pearson's $\rho$.

### scRNA-seq pseudo-bulks

I then proceeded to apply the method to *in-silico* simulated bulk RNA-seq data
("pseudo-bulks") generated from scRNA-seq data, to assess its performance on
actual expression data with precisely known cell type abundances and expression
profiles. I used single cell RNA sequencing data consisting of transcript count
data breast cancer tumor samples from @wu.2021 (Gene Expression Omnibus, GEO
accession
[GSE176078](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE176078)). It
contains 100'064 cells, 29'733 genes, from 26 samples. The cells are annotated
as belonging to one of nine cell types, with further subtype information
available. Since the dataset provided by @wu.2021 is already filtered for high
quality cells, I performed no additional cell quality control.

To construct the reference profiles, I averaged the per gene expression counts
from @wu.2021 across all cells of the same cell type. To explore the effects of
restricting the set of genes used for deconvolution on estimation accuracy for
both cell type abundances and cancer expression, I applied a set of selection
criteria to the genes of the reference. This comprised basic gene quality
control, during which I filtered genes to be expressed in at least
`r txt_ss_stc("min_gene_expr_cell_count")` cells, removed genes which could
potentially introduce batch effects, and removed non-protein coding genes. In
this, I generally followed the methodology from @chu.2022, except I did not
remove genes from sex chromosomes as these might play a role in breast cancer.
Also, I assigned each gene a marker score, quantifying its likely usefulness as
a gene in the deconvolution reference. Genes with a good score would have an
expression signature across cell types which would allow for clear
identification of just a single cell type by having particularly high or low
expression in just that cell type. I explored multiple ways to determine this
score during preliminary experiments [DESeq2 @love.2014; Hampel filter
@davies.1993], but ultimately chose a simple Wilcoxon test [@wilcoxon.1945] for
comparing each cell type to the pooled remaining cell types
[via `FindAllMarkers` from the R Seurat package v.5, @hao.2023] for its
combination of relative simplicity and accuracy. The marker score for the
Wilcoxon test based marker selection was the test p-Value [adjusted for multiple
testing via the Holm-Bonferroni method @holm.1979]. I only considered genes
differentially expressed in a single cell type with at $p_{adj} < 0.05$ as
marker genes, with lower values being considered better. I contrasted the
wilcoxon marker selection method with choosing a random value for the marker
score to ensure any changes in performance were not simply due to the restricted
size of the set of marker genes.

I computed reference profiles across a spectrum of parameters, one reference for
each combination. For each marker selection strategy I used a threshold
selecting the top `r txt_ss_stc("thresholds")` of the best scoring marker genes.
I also contrasted across including the cancer cell type or not, and including
either only genes passing transcript quality control or all marker genes for a
reference.

I generated `r txt_ss_stc("n_pseudobulk")` pseudo-bulks by randomly sampling
`r txt_ss_pb("nominal_n_cell")` cells (twice the median number of cells per
sample in the data) with replacement from the overall count matrix from
@wu.2021, stratified by cell type. Cell type fractions
$\mathbf{f}_{\text{norm}}$ were also randomly selected by first choosing each
cell type's fraction uniformly at random, and then normalizing the fraction of
all non-cancer cell types to sum to the complement of the fraction of the cancer
cell type:

\begin{equation*}
  \begin{aligned}
    \mathbf{f}_{\text{raw}} &\sim \mathcal{U}(0, 1) \\
    \left( f_{\text{norm}} \right)_j &= \frac{
      \left( f_{\text{raw}} \right)_j
    } {
      \sum_{j=1}^{m-1} {\left( f_{\text{raw}} \right)_j}
    } - {\left( f_{\text{raw}} \right)_m}
  \end{aligned} \\
  \text{with} \ 1 \leq j \leq (m - 1) \in
  \text{non cancer, and} \ m \in \text{cancer}
\end{equation*}

This was to allow for a broad range of cancer cell type fractions, which would
have been restricted to lower values due to the normalization.

<!-- TODO Mention scaling of expected expression & averaging across
deconvolutions of the same parameters. Don't forget to do the latter across
sections -->

I then deconvoluted each pseudo-bulk using each reference and calculated
Pearson's $\rho$ between true and estimate values for both cell type
concentrations and cancer cell type expression.

## Evaluation

After ensuring my method behaves as expected, I compared the performance to an
established method. First, I tested performance on correctly inferring true
cancer expression in both pseudo-bulks and actual RNA-sequencing data. Second, I
used cancer expression predictions of bulk RNA-seq data to train machine
learning models predicting tumor subtype and progression free interval (PFI)
and compared the performance of both BayesPrism and my method to models trained
on raw bulk data.

### Comparison to BayesPrism

To compare my transcriptome cleaning method to an established state-of-the-art
method of estimating cell type specific expression profiles from bulk RNA-seq
data, I applied both my method and BayesPrism to tumor sample derived
pseudo-bulks, and to actual bulk RNA-seq samples, both from @wu.2021. A subset
of tumor samples used in their paper has also been processed via bulk RNA-seq.
Of the three high resolution *in-silico* dissection methods mentioned before,
BayesPrism seems the best suited for a comparison here. It is specifically
designed for tumor samples and integrates well with my existing analysis
framework since it is also written in `R`.

The general methodology for the comparison to BayesPrism was similar to the
previous scRNA-seq based [section](#scrna-seq-pseudo-bulks), however, I derived
pseudo-bulks not from random cell indices, but rather used all cells belonging
to a distinct tumor sample in the original data. This was done to be able to
compare results between pseudo-bulks and actual bulk RNA-seq data. In addition
to the pseudo-bulk data, I retrieved bulk RNA-seq data available for a subset of
samples in @wu.2021. Since the bulk data was only available for 24 of all 26
tumor samples, only those 24 samples were used for both bulk and pseudo-bulk
data.

I also computed reference profiles similarly to the scRNA-seq based pseudo-bulks
[section](#scrna-seq-pseudo-bulks), except that I did not include the same
contrasting across reference parameters to simplify the analysis. I only
included the parameters expected to lead to optimal results, namely including
cancer splitting, Wilcoxon marker selection, and marker gene quality control.

Lastly, I deconvoluted every bulk and pseudo-bulk using every reference as
before, but this time I used BayesPrism in addition to the NNLS method. I
extracted and processed residuals from my method as in the scRNA-seq based
pseudo-bulks [section](#scrna-seq-pseudo-bulks). Extracting the predictions for
cancer expression from BayesPrism is straightforward as it computes cell type
expression predictions for all cell types on the original scale. However, it is
not capable of estimating gene expression for non-marker genes, so comparisons
bettween it and my method are based on a different number of genes. As before, I
used Pearson's $\rho$ to assess the relationship of predicted expression to
actual expression.

### Prediction

As the final evaluation of the method, I compared the predictive power of
machine learning models trained on both estimated cancer expression data to
models trained on bulk RNA-seq data alone. For this, I used bulk RNA-seq data of
breast cancers annotated with clinical data from the Cancer Genome Atlas [TCGA,
@colaprico.2016].

<!-- TODO Expand on PAM50 subtype & PFI. -->

The data comprised all samples from 1'095 patients in the TCGA-BRCA project with
bulk RNA-seq data available. I also retrieved data on survival endpoints derived
from curated clinical data from @liu.2018 for the corresponding tumor samples. I
used this data to predict both the PAM50 subtype [@parker.2009] of a tumor and
the progression-free interval (PFI) for the patient. The PAM50 subtype
classifies a breast cancer tumor into one of five categories ("Basal", "Her2",
"LumA", "LumB", "Normal") based on the microarray expression of a set 50 genes.
The PFI on the other hand is a property of the patients disease progression.
Compared to the overall survival of the patient which may be of greater
interest, it has the advantage of greater avalability of data due to shorter
followup times [@liu.2018]. To ensure consistent data, I restricted analysis to
samples of primary solid tumors (excluding normal and metastatic tissue
samples). After that, I was left with `r txt_pr_cat_stat("n_sample")` tumor
samples with data on the PAM50 subtype. Since the PFI is a variable on the
patient level, I restricted the bulk data to one sample per patient, chosing the
first sample recorded. This left `r txt_pr_srv_stat("n_sample")` samples with
PFI data.

To generate expression estimates, I applied my method to all bulk data samples
by deconvoluting it using references derived from the @wu.2021 scRNA-seq data
like in the previous sections, except with a smaller set of thresholds
(`r txt_pr_stc("thresholds")`) on marker gene scores. Like in the
[section](#comparison-to-bayesprism) comparing my method to BayesPrism, I also
ran the latter method on the same data to later compare the prediction accuracy
of models trained on cancer expression estimations from either method. To add
more context to the observed differences in the performance the models trained
on bulk data and estimated cancer expression, I also trained models using the
estimated combined TME expression. For my method, this was simply the fitted
values of the deconvolution model ($\mathbf{\hat{b}}$, see the
[method overview](#transcriptome-cleaning-overview)). For BayesPrism, this was
represented by the sum of gene expression predictions across all non-cancer cell
types. As BayesPrism is not able to estimate expression for non-marker genes,
there is a possibility that differences in performances of the models trained on
the expression estimated are due to the differences in the amount of genes. To
address this, I also trained models on bulk data with gene sets restricted to
each set of genes from the cancer / TME expression estimates.

I transformed each feature set (i.e., raw bulk, cancer, and TME expression) onto
a logarithmic scale ($\mathbf{x}_{\text{trans}} = \log_{10}{\left( \mathbf{x} +
1 \right)}$, only if it was not already on that scale, as was the case for
expression estimates from my method), and split each into training and test data
at a fraction of `r txt_pr_stc("train_frac")` for training and
`r txt_pr_stc("test_frac")` for testing. Using the preprocessing facilities of
the `caret` package [@kuhn.2008], I performed removal of zero-variance genes,
centering, scaling, and finally dimensionality reduction via principal component
analysis (at a threshold of 95% of variance explained for including components)
on the training set. The same procedure was applied to the testing data using
the same parameters for each step as for training data to avoid information
leakage.

<!-- TODO Expand on model objectives used? -->

To train machine learning models predicting the PAM50 subtype of a tumor sample,
I used a linear kernel support vector regression (SVR) approach via the `caret`
package [@kuhn.2008], optimizing simple accuracy of class predictions. Models
were trained using `r txt_pr_cat("cv_fold")`-fold cross-validation, repeated
`r txt_pr_cat("cv_repeat")` times. I used the "Synthetic Minority Oversampling
Technique" [SMOTE, @chawla.2002] for resampling during each training iteration
to ensure balanced representation of classes.

To predict the PFI of a patient from expression data, I used random survival
forests as implemented in the `randomForestSRC` package [@ishwaran.2008]. Here,
I trained random survival forest models with `r txt_pr_srv("n_tree")` trees by
first performing hyperparameter tuning for finding the optimal parameters for
the data. These were the number of randomly chosen variables for splitting at
each node (parameter `mtry`), and the minimal number of cases that a terminal
node of a tree may contain (parameter `nodesize`). The performance for random
survival forests is measured using the C-index [@harrell.1982], comparing the
observed ordering of events taking place to the predicted.

I evaluated each model on datasets bootstrapped from the test samples using the
averaged performance metric across the bootstrap datasets as the final model
accuracy. For this, I sampled tumor samples from the test data with replacement,
using `r txt_pr_evl("sample_frac")` of the size of the test data for each
evaluation dataset and repeating the process `r txt_pr_evl("n_repeat")` times.
