# Methods & Data

```{r method-setup, include = FALSE}
import::here("here", "here")
import::here("knitr", "kable")
import::here("magrittr", .all = TRUE)
import::here("purrr", "pluck", "map_vec")

here::i_am("bookdown/02-methods.Rmd")

import::here(
  "utils.R",
  "load_param_table_dir",
  "formatted_yaml_value",
  .character_only = TRUE,
  .directory = here("modules")
)

# Suppress chunk output by default.
knitr::opts_chunk$set(echo = FALSE)

param_table_dir <- here("cancer-cleaning-output/param_tables")
param_tables <- load_param_table_dir(param_table_dir)

# Define short functions for inserting text, so as not to break flow too much.

txt_rs_stc <- function(name) {
  # Use global param_tables.
  formatted_yaml_value(
    param_obj = param_tables$yaml_objs$rnd_sim$static_parameters,
    value_name = name
  )
}

txt_ss_stc <- function(name) {
  # Use global param_tables.
  formatted_yaml_value(
    param_obj = param_tables$yaml_objs$scrna_sim$static_parameters,
    value_name = name
  )
}

txt_ss_pb <- function(name) {
  # Use global param_tables.
  formatted_yaml_value(
    param_obj = param_tables$yaml_objs$scrna_sim$pbulk_stats,
    value_name = name
  )
}

txt_pr_stc <- function(name) {
  # Use global param_tables.
  formatted_yaml_value(
    param_obj = param_tables$yaml_objs$pred$static_parameters %>%
      # There are sub-lists to this param_obj, but we don't want those.
      extract(!map_vec(., is.list)),
    value_name = name
  )
}

txt_pr_cat <- function(name) {
  # Use global param_tables.
  formatted_yaml_value(
    param_obj = param_tables$yaml_objs$pred$static_parameters$categorical,
    value_name = name
  )
}

txt_pr_cat_stat <- function(name) {
  # Use global param_tables.
  formatted_yaml_value(
    param_obj = param_tables$yaml_objs$pred$categorical_stat,
    value_name = name
  )
}

txt_pr_srv <- function(name) {
  # Use global param_tables.
  formatted_yaml_value(
    param_obj = param_tables$yaml_objs$pred$static_parameters$survival,
    value_name = name
  )
}

txt_pr_srv_stat <- function(name) {
  # Use global param_tables.
  formatted_yaml_value(
    param_obj = param_tables$yaml_objs$pred$survival_stat,
    value_name = name
  )
}

txt_pr_evl <- function(name) {
  # Use global param_tables.
  formatted_yaml_value(
    param_obj = param_tables$yaml_objs$pred$static_parameters$evaluation,
    value_name = name
  )
}
```

## Transcriptome cleaning overview

Following from the basic deconvolution model of equation
\@ref(eq:basic-matrix-deconv), the problem becomes tractable when the signature
matrix $\mathbf{S}$ is already known as it is then reduced to a system of linear
equations for each bulk $k$:

\begin{equation*}
  \mathbf{B}_{\cdot k} = \mathbf{S} \mathbf{C}_{\cdot k}
  \qquad \forall 1 \leq k \leq p
\end{equation*}

To reduce the solution space, usually a non-negativity constraint is placed on
elements of $\mathbf{C}$, as a bulk can't contain negative concentrations
[@venet.2001]. Adding this constraint, and considering the bulks $\mathbf{b}$
and associated concentration vectors $\mathbf{c}$ independently the problem can
be formulated as

\begin{equation*}
  \mathbf{b} = \mathbf{S} \mathbf{c}
  \qquad s.t.\ \mathbf{c}_i \geq 0 \; \forall 1 \leq j \leq m
\end{equation*}

This can then be solved using a least-squares method with the objective function

\begin{equation}
  \min_{\mathbf{c} \geq 0} \|\mathbf{Sc} - \mathbf{b}\|^2
\end{equation}

Under the assumption that cancer cells vary stronger in their expression than
the other cells in the microenvironment, we can expect the residuals to contain
much of this excess variation. It may be possible to further enhance the signal
of pure expression of cancer cells by simply not including the reference profile
for cancer cells during deconvolution. While this would certainly lead to less
accurate results for the prediction of cell type abundance as some proportion of
cancer cell gene expression would be erroneously attributed to other cell types
[although this issue seems to be already present in the ideal case, see
@aran.2017], the residuals might then more accurately reflect the patterns of
cancer cell type expression as when they are already accounted for by the
inclusion of the cancer cell type reference profile.

Prior information on the expression profiles of the cell types present in a set
of bulk RNA-seq samples may be obtained in different ways. Relatively simple
approaches like expression profiling of cultured purified cell lines allow for
characterization of cell type specific expression profiles at low cost and
effort, but require normalization to eliminate bias from differing cell counts.
More complex methods allowing for single cell level expression quantification
like micro-dissection, fluorescence-activated cell sorting, and more recently
scRNA-seq do not have this problem, but are limited in application due to their
cost. Single cell based reference profiles have a further advantage in
least-squares deconvolution since they allow quantification of actual cell type
counts rather than proportions only, since the profile corresponds to the
expression of a single cell. For this reason, along with the need to construct
pseudo bulks for which single-cell data is needed, I generally use scRNA derived
references here (except for random simulations). To construct reference profiles
from scRNA-seq data, I simply averaged all cells annotated as belonging to the
same cell type. I also restricted the set of genes used for deconvolution to the
most discriminant ones (see the later
[pseudobulk section](#scrna-seq-pseudo-bulks)), to increase deconvolution
accuracy and reduce computation time.

<!-- Talk about previous work on marker genes for deconvolution? -->

After reference creation, the computation of residuals as a measure for true
expression of cancerous cells is relatively straightforward. First the
untransformed bulk RNA-seq data is deconvoluted using the also untransformed
reference profiles. Using untransformed data has been shown to yield more
accurate results for least-squares based deconvolution of microarray data
[@zhong.2011], which I saw to hold true for the data I use here in preliminary
experiments. Throughout this work, I always used the `nnls` package
[@katharinem.mullen.2023] in the `R` programming language [@rcoreteam.2023] for
this step. The deconvolution model estimates for cell type counts $\mathbf{c}$
are then used to compute the *full* predicted gene expression vector of the
deconvolution model $\mathbf{\hat{b}}$ using all genes from the reference
profile, not only the marker genes used in deconvolution. From this the
residuals $\epsilon$ can then be computed:

\begin{equation*}
  \epsilon = \mathbf{b} - \mathbf{\hat{b}}
\end{equation*}

<!-- FIXME Add a diagram explaining the relationship between fitted values,
residuals, and cancer expression estimation. -->

For real-world applications (i.e., everything except
[normally distributed simulation](#normally-distributed-simulation)), the
absolute value of the residuals was used. This was done since deconvolution
residuals can inherently take both positive and negative values, but here are
used to estimate count data which is non-negative. Using the absolute values
also allows log transformation of the residuals (adding a pseudo-count of one to
preserve values of zero on the original scale; $\mathbf{x}_{\text{trans}} =
\log_{10}{\left( \mathbf{x} + 1 \right)}$), which was done so that the variance
of the residuals stays reasonably consistent across the spectrum of actual and
predicted gene expression values, and summary statistics assuming a near normal
distribution (i.e., Pearsons $\rho$) could be used.

## Proof of concept

Before applying my method to real-world problems, I carried out two analyses
assessing its performance under ideal conditions. First, I explored the method's
behavior when applied to normally distributed data with varying levels of noise
added, and then quantified its performance on more realistic data using
scRNA-seq derived pseudo-bulk data.

### Normally distributed simulation

To demonstrate the principle of the method, I first generated model expression
profiles, simulated measurements of expression quantification, and analyzed the
behavior of my method on it (see Tables \@ref(tab:rnd-sim-params) &
\@ref(tab:rnd-sim-ratios) for all parameters and their values used for the
simulation). The simulated expression profiles $\mathbf{S}_{sim}$ were generated
by sampling expression data for $n$ transcripts & $m$ cell types from a normal
distribution:

\begin{equation*}
  \mathbf{S}_{sim} \sim \mathcal{N}(0, \ \sigma_{gene}^2)
\end{equation*}

For each set of expression profiles, I then simulated the result of a bulk
RNA-seq experiment $\mathbf{b}_{sim}$ by convoluting randomly sampled cell type
counts with their respective reference profiles. For this, I first sampled cell
type counts $\mathbf{c}_{sim}$ for all cell types uniformly at random:

\begin{equation*}
  \mathbf{c}_{sim} \sim \mathcal{U}(0, 1)
\end{equation*}

As I wanted to simulate biological variability, I could not carry out the
convolution by simple matrix multiplication of $\mathbf{S}_{sim}$ and
$\mathbf{c}_{sim}$, but needed to simulate individual cells. I did this by
assembling a matrix of individual cell expression $\mathbf{P}$ through repeating
cell type reference profiles as often as their simulated count:

\begin{equation*}
    \mathbf{P} = \left( \begin{array}{c|c|c|c}
        \left(
          \mathbf{S}_{\text{sim}, \ \cdot 1}
        \right)_{\times \mathbf{c}_{\text{sim}, 1}} &
        \left(
          \mathbf{S}_{\text{sim}, \ \cdot 2}
        \right)_{\times \mathbf{c}_{\text{sim}, 2}} &
        \cdots &
        \left(
          \mathbf{S}_{\text{sim}, \ \cdot m}
        \right)_{\times \mathbf{c}_{\text{sim}, m}}
    \end{array} \right)
\end{equation*}

Then, to simulate the deviation of individual cells from their reference
profile, I added a matrix of normally distributed noise
$\mathbf{N}_{\text{cancer homo.}}$:

\begin{equation*}
  \mathbf{N}_{\text{cancer homo.}} \sim \mathcal{N}(0, \ \sigma_{cellvar}^2)
\end{equation*}

I also optionally simulated cancer cells having more heterogeneous expression
($\mathbf{N}_{\text{cancer het.}}$) by using a greater standard deviation for
simulating their profile deviation, for this I multiplied it by a factor of $x$.

\begin{equation*}
  \begin{aligned}
    \mathbf{N}_{\text{non cancer}} &\sim \mathcal{N}(0, \ \sigma_{cellvar}^2) \\
    \mathbf{N}_{\text{cancer}} &\sim \mathcal{N}(
      0, \left( \sigma_{cellvar} * x \right)^2
    ) \\
    \\
    \mathbf{N}_{\text{cancer het.}} &= \left( \begin{array}{c|c}
      \mathbf{N}_{\text{non cancer}} & \mathbf{N}_{\text{cancer}}
  \end{array} \right)
  \end{aligned}
\end{equation*}

The final matrices of simulated cell expression $\mathbf{Q}$, using both
versions of $\mathbf{N}$ were then simply:

\begin{equation*}
  \begin{aligned}
    \mathbf{Q}  &= \mathbf{P} + \mathbf{N}
  \end{aligned}
\end{equation*}

To obtain the bulk vector for the mixture $b_{\text{sim}}$, I just summed up the
expression of each transcript $i$ across the $m$ cells and simulated technical
noise $\mathbf{e}$ from the sequencing process as normally distributed additive
noise:

\begin{equation*}
  \mathbf{e} \sim \mathcal{N}(0, \sigma_{\text{tech}}^2)
\end{equation*}

\begin{equation*}
  b_{\text{sim}, i} = \sum_{j = 1}^{m} \left(
    q_{i,j}
  \right) + e_j
  \quad \forall \ 1 \leq i \leq n
\end{equation*}

I varied $\sigma_{\text{tech}}$ across a range of values to understand my
method's behavior under conditions of both relatively high and low technical
noise (see Table \@ref(tab:rnd-sim-ratios)). Finally, I deconvoluted the
resulting set of simulated bulks with the varying amounts of technical noise and
optionally heterogeneous cancer expression again with associated reference
expression profiles, each either including or excluding the designated cancer
cell type. I examined the relationship between the distribution of residuals to
the true expression profile of the cancerous cell type using Pearson's $\rho$. I
repeated this `r txt_rs_stc("n_repeats")` times for each level of technical
noise and averaged results and calculated 95% confidence intervals (CIs) across
replicates.

```{r rnd-sim-params}
kable(
  param_tables$table_objs$rnd_sim$static_parameters,
  caption = paste(
    "Simulation parameters used to evaluate my method's performance on",
    "normally distributed simulated data."
  ),
  # Don't escape the `$` symbols, we want formulas to be rendered in LaTeX
  # output.
  escape = FALSE
)
```

```{r rnd-sim-ratios}
kable(
  param_tables$table_objs$rnd_sim$variable_parmeter_table,
  caption = paste(
    "Levels of techincal noise used for evaluating my method's performance on",
    "normally distributed simulated data."
  ),
  # Don't escape the `$` symbols, we want formulas to be rendered in LaTeX
  # output.
  escape = FALSE
)
```

### scRNA-seq pseudo-bulks

I then proceeded to apply the method to *in-silico* simulated bulk RNA-seq data
("pseudo-bulks") generated from scRNA-seq data, to assess its performance on
actual expression data with precisely known cell type abundances and expression
profiles. I used single cell RNA sequencing data consisting of transcript count
data breast cancer tumor samples from @wu.2021 (Gene Expression Omnibus, GEO
accession
[GSE176078](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE176078)). It
contains 100'064 cells, 29'733 genes, from 26 samples. The cells are annotated
as belonging to one of nine cell types, with further subtype information
available. Since the dataset provided by @wu.2021 is already filtered for high
quality cells, I performed no additional cell quality control.

To construct the reference profiles, I averaged the per gene expression counts
from @wu.2021 across all cells of the same cell type. To explore the effects of
restricting the set of genes used for deconvolution on estimation accuracy for
both cell type abundances and cancer expression, I applied a set of selection
criteria to the genes of the reference. This comprised basic gene quality
control, during which I filtered genes to be expressed in at least
`r txt_ss_stc("min_gene_expr_cell_count")` cells, removed genes which could
potentially introduce batch effects, and removed non-protein coding genes. In
this, I generally followed the methodology from @chu.2022, except I did not
remove genes from sex chromosomes as these might play a role in breast cancer.

I also assigned each gene a marker score, quantifying its likely usefulness as a
marker gene in the deconvolution reference. Genes with a good score would have
an expression signature across cell types which would allow for clear
identification of just a single cell type by having particularly high or low
expression in just that cell type. I explored multiple ways to determine this
score during preliminary experiments [DESeq2 from @love.2014; and Hampel filter
from @davies.1993], but ultimately chose a simple Wilcoxon test
[@wilcoxon.1945] for comparing each cell type to the pooled remaining cell types
[via `FindAllMarkers` from the `R` Seurat package v.5, @hao.2023] for its
combination of relative simplicity and accuracy. The marker score for the
Wilcoxon test based marker selection was the test p-Value [adjusted for multiple
testing via the Holm-Bonferroni method, @holm.1979]. I only considered genes
differentially expressed in a single cell type with at $p_{adj} < 0.05$ as
marker genes, with lower values being considered better. The wilcoxon method of
marker selection was contrasted with choosing a random value for the marker
score to ensure any changes in performance were not simply due to the restricted
size of the set of marker genes. Since the Wilcoxon test based markers were the
same across deconvolutions as they were a property of the underlying scRNA-seq
data, the random values used were also constant for each reference profile.

I computed reference profiles across a spectrum of parameters, one reference for
each combination. These included the two marker selection strategies, the
thresholds selecting the top `r txt_ss_stc("thresholds")` of the best scoring
marker genes (chosen for empahsis on lower thresholds), and whether the cancer
cell type expression profile was included.

I generated `r txt_ss_stc("n_pseudobulk")` pseudo-bulks by sampling
`r txt_ss_pb("nominal_n_cell")` cells (twice the median number of cells per
sample in the data) out of the overall cells in the count matrix from @wu.2021.
Sampling was done with replacement and stratified by cell type. For this, cell
type fractions $\mathbf{f}_{\text{norm}}$ were randomly selected by first
choosing each cell type's fraction uniformly at random, and then normalizing the
fraction of all non-cancer cell types to sum to the complement of the fraction
of the cancer cell type:

\begin{equation*}
  \begin{aligned}
    \mathbf{f}_{\text{raw}} &\sim \mathcal{U}(0, 1) \\
    f_{\text{norm}, j} &= \frac{
      f_{\text{raw}, j}
    } {
      \sum_{j=1}^{m-1} {f_{\text{raw}, j}}
    } - {f_{\text{raw}, m}} \\
    \text{with} \ 1 \leq j \leq (m - 1) &\in
    \text{non cancer, and} \ m \in \text{cancer}
  \end{aligned}
\end{equation*}

This was to allow for a broad range of cancer cell type fractions, which would
have been restricted to lower values due to the normalization.

I then deconvoluted each pseudo-bulk using each reference and calculated the
average Pearson's $\rho$ and its 95% CI between true and estimated values of
cancer cell type expression across all deconvolutions with the same set of
parameters.

## Evaluation

After exploring the behavor of my method under ideal conditions, I compared its
performance to an established method. First, I tested performance on correctly
inferring true cancer expression in both pseudo-bulks and actual RNA-sequencing
data. Second, I used cancer expression predictions of bulk RNA-seq data to train
machine learning models predicting tumor subtype and progression free interval
(PFI) and compared the performance of both BayesPrism and my method to models
trained on raw bulk data.

### Comparison to BayesPrism

To compare my transcriptome cleaning method to an established state-of-the-art
method, I applied both my method and BayesPrism to pseudo-bulks & bulk RNA-seq
data of tumor samples from @wu.2021. I chose BayesPrism out of the three high
resolution *in-silico* dissection methods mentioned above since it is
specifically designed for tumor samples and integrates well with my existing
analysis framework since both are written in `R`.

The general methodology for the comparison to BayesPrism was similar to the
previous scRNA-seq based [section](#scrna-seq-pseudo-bulks). However, I derived
pseudo-bulks not from random cell indices, but rather used all cells belonging
to a distinct tumor sample in the original data. As mentioned, a subset of 24
tumor samples examined by @wu.2021 has also been processed bulk RNA-seq,
allowing me to directly compare performance on pseudo-bulk and real-world bulk
RNA-seq data. For comparability, only those 24 samples were then used for both
bulk and pseudo-bulk data. To compute references, I used the same set of
thresholds on the marker genes, but did not include the contrasting across other
reference parameters to simplify the analysis. For these other parameters, I
used the values expected to lead to optimal results, namely including cancer
splitting, Wilcoxon marker selection, and marker gene quality control. Lastly, I
deconvoluted every bulk and pseudo-bulk using every reference as before, except
using both my method and BayesPrism.

I extracted and processed residuals from my method the same as in the scRNA-seq
based pseudo-bulks [section](#scrna-seq-pseudo-bulks). Extracting the
predictions for cancer expression from BayesPrism is straightforward as it
computes cell type expression predictions for all cell types on the original
scale. However, it is not capable of estimating gene expression for non-marker
genes, so comparisons between it and my method are based on a different number
of genes. As before, I used the average Pearson's $\rho$ with 95% CI across
deconvolutions of the same parameters to assess the relationship of predicted
expression to actual expression.

### Prediction

As the final evaluation of the method, I compared the predictive power of
machine learning models trained on estimated cancer expression data to models
trained on bulk RNA-seq data alone. For this, I used bulk RNA-seq data of breast
cancers annotated with clinical data from the Cancer Genome Atlas [TCGA,
@colaprico.2016].

The data comprised all samples from 1'095 patients in the TCGA-BRCA project with
bulk RNA-seq data available. I also retrieved data on survival endpoints derived
from curated clinical data from @liu.2018 for the corresponding tumor samples. I
used this data to predict both the PAM50 subtype [@parker.2009] of a tumor and
the progression-free interval (PFI) for the patient. The PAM50 subtype
classifies a breast cancer tumor into one of five categories ("Basal", "Her2",
"LumA", "LumB", "Normal") based on the microarray expression of a set 50 genes.
The PFI on the other hand, is a property of the patients' disease progression.
Compared to the overall survival of the patient which may be of greater
interest, it has the advantage of greater availability of data due to shorter
followup times [@liu.2018]. To ensure consistent data, I restricted analysis to
samples of primary solid tumors (excluding normal and metastatic tissue
samples). After that, I was left with `r txt_pr_cat_stat("n_sample")` tumor
samples with data on the PAM50 subtype. Since the PFI is a variable on the
patient level, I restricted the bulk data for training and evaluating models
predicting this variable to one sample per patient and choosing the first sample
recorded. This left `r txt_pr_srv_stat("n_sample")` samples with PFI data.

To generate expression estimates, I applied my method to all bulk data samples,
deconvoluting it using references derived from the @wu.2021 scRNA-seq data as in
the previous sections, except with a smaller set of thresholds
(`r txt_pr_stc("thresholds")`) on marker gene scores. To put the results into
context, I also ran BayesPrism on the same data again. However, as BayesPrism is
not able to estimate expression for non-marker genes, there is a possibility
that differences in performances of the models trained on the expression
estimates are confounded by the differences in the number of genes. To address
this, I also trained models on bulk data with gene sets restricted to each set
of genes from the cancer expression estimates.

I ensured each feature set (i.e., all raw bulk and cancer expression estimates)
was transformed onto a logarithmic scale ($\mathbf{x}_{\text{trans}} =
\log_{10}{\left( \mathbf{x} + 1 \right)}$), and split each into training and
test data at a fraction of `r txt_pr_stc("train_frac")` for training and
`r txt_pr_stc("test_frac")` for testing. Using the preprocessing facilities of
the `caret` package [@kuhn.2008], I performed removal of zero-variance genes,
centering, scaling, and finally dimensionality reduction via principal component
analysis (at a threshold of 95% of variance explained for including components)
on the training set. The same procedure was applied to the testing data using
the same parameters for each step as for training data to avoid information
leakage.

<!-- TODO Expand on model objectives used? -->

To train machine learning models predicting the PAM50 subtype of a tumor sample,
I used a linear kernel support vector machine (SVM) approach via the `caret`
package [@kuhn.2008], optimizing simple accuracy of class predictions. Models
were trained using `r txt_pr_cat("cv_fold")`-fold cross-validation, repeated
`r txt_pr_cat("cv_repeat")` times. I used the "Synthetic Minority Oversampling
Technique" [SMOTE, @chawla.2002] for resampling during each training iteration
to ensure balanced representation of classes.

To predict the PFI of a patient from expression data, I used random survival
forests as implemented in the `randomForestSRC` package [@ishwaran.2008]. Here,
I trained random survival forest models with `r txt_pr_srv("n_tree")` trees by
first performing hyperparameter tuning for finding the optimal parameters for
the data. These were the number of randomly chosen variables for splitting at
each node (parameter `mtry`), and the minimal number of cases that a terminal
node of a tree may contain (parameter `nodesize`). The performance for random
survival forests is measured using the C-index [@harrell.1982], mesuring the
concordance in the ordering of actual events and of predicted ones.

I evaluated each model on datasets bootstrapped from the test samples using the
averaged performance metric and its 95% CI across the bootstrap datasets as the
final model accuracy. For this, I sampled tumor samples from the test data with
replacement, using `r txt_pr_evl("sample_frac")` of the size of the test data
for each evaluation dataset and repeating the process `r txt_pr_evl("n_repeat")`
times.
