# Results

```{r res-setup, include = FALSE}
import::here("here", "here")
import::here("knitr", "include_graphics")

# Suppress chunk output by default.
knitr::opts_chunk$set(echo = FALSE, fig.pos = "h")

here::i_am("bookdown/03-results.Rmd")

import::here(
  "utils.R",
  "main_plot_handles_from_path",
  .character_only = TRUE,
  .directory = here("modules")
)

analysis_root <- "cancer-cleaning-output"
main_plot_dir <- "main_plots"
main_plot_path <- here(paste(analysis_root, main_plot_dir, sep = "/"))

plot_prefixes <- list(
  "rnd_sim" = "random_deconv_simulation_metric_summary_plot",
  "pbulk_cexpr_acc" = "simulation_true_v_predict_cancer_corr_plot",
  "pbulk_acc_v_prop" = "simulation_cancer_acc_v_prop_plot",
  "bp_cexpr_acc" = "bayes_prism_true_v_predict_cancer_corr_plot",
  "bp_acc_v_prop" = "bayes_prism_cancer_acc_v_prop_plot",
  "pred_cat_perf" = "categorical_prediction_performance_plot",
  "pred_srv_perf" = "survival_prediction_performance_plot"
)

plot_handles <- main_plot_handles_from_path(main_plot_path, plot_prefixes)

plot_paths <- plot_handles$plot_paths
plot_caps <- plot_handles$plot_caps
```

## Proof of concept

### Normally distributed simulation {#res-normally-dist-sim}

During simulation using normally distributed data deconvPure's performance
behaved as expected. The estimation accuracy for cancer expression via
deconvolution model residuals (Figure \@ref(fig:rnd-sim-plt)) shows clear
differences across simulation parameters, with the largest difference being
across reference type.

The average estimation accuracy for cancer expression, measured by the
correlation of true and estimated cancer expression, under the homogeneous
cancer expression model using a reference with cancer profiles was low across
the remaining parameters. All differences in averages mentioned are
statistically significant, based on no 95% CI overlap, see Supp. Table
\@ref(fig:rnd-sim-ground-truth) for detailed values. When modeling bulk mixtures
without cell variation, the average correlation was exactly zero throughout
(with strong variation in the case of neither technical noise nor cell vatiation
added due to numerical instability from extemely small residual values). When
adding cell variation, some differences in accuracy emerged: For simulations
where cancer cells behaved like others, absent noise and noise equal to
biological variability had the same accuracy. The high technical noise group was
slightly worse and very high noise led to very low accuracy. Under the model of
cancer cells varying stronger than other cell type's cells, there was an
appreciable improvement in accuracy compared to the homogeneous model, with the
behavior of individual groups remaining largely similar to the previous model.
The exception to that was high group, which no longer showed a difference to the
groups with lower technical noise.

As mentioned, the largest improvement can be seen when removing the cancer
expression profile from the reference. Here, when not including any cell
variation, deconvPure is able to perfectly estimate cancer expression, i.e., the
deconvolution residuals correlate perfectly with the expression profile of the
bulk mixture. Again, equal and high noise groups showed little difference
(performance only distinct on none vs. high) and high noise even showing medium
accuracy. Including cell variation led to a slight drop in estimation accuracy
for the three lowest noise groups, now they varied around 0.9 rather than close
to 1.0, but no clear effect for very high technical noise. Varying cancer
expression more strongly across cells had no clear effect either.

During the simulation experiment, I naturally observed very little similarity
between patterns of estimation accuracy and inherent information when average
estimation accuracy was already low (Supp. Fig. \@ref(fig:rnd-sim-acc-abund)).
Modeling cancer expression as more variable than other celltypes increased while
still including the cancer reference during deconvolution resulted in estimation
accuracies slighlty above inherent information, but the effect was only present
for low simulated tumor purities. For all the parameter combinations resulting
in high overall accuracy on the other hand the estimation accuracy was always
higher than the association of bulk and cancer, showing a benefit of the
approach over just using bulk expression data. That benefit, however, diminished
for higher tumor purities as inherent information of the bulk rose in turn.

```{r rnd-sim-plt, fig.cap = plot_caps$rnd_sim}
include_graphics(plot_paths$rnd_sim)
```

### scRNA-seq pseudo-bulks {#res-scrna-seq-pseudo-bulks}

When benchmarking deconvPure on pseudo-bulks derived from scRNA-seq data, the
accuracy of estimated cancer expression from absolute values of model residuals
was high (Figure \@ref(fig:pbulk-cexpr-acc-plt)) with only minor differences in
average correlation across parameters. Again all differences in averages
mentioned are based on 95% CI overlap, actual values can be found in Supp. Table
\@ref(tab:pbulk-cexpr-acc-tab).

When including cancer expression in the reference profiles, there was a clear
difference between marker selection methods. Wilcoxon test based markers showed
higher average correlation compared to random marker selection across all
thresholds on the number of markers. Also, while there was very little variation
in accuracy across thresholds for random markers, on the second-tightest
threshold for Wilcoxon based markers performance was significantly worse than on
the remaining thresholds. When excluding the cancer expression profile from the
reference, performance further increased across all other parameters, except for
the tightest marker threshold on Wilcoxon.

General patterns were similar between in- or excluding the cancer expression
profile but with some exceptions. In the latter case and for the loosest marker
threshold, random markers resulted in slightly but significantly worse average
correlation than looser thresholds, which in turn no longer clearly differed
from the second-tightest threshold on Wilcoxon markers. Lastly, the within group
differences for Wilcoxon markers increased such that the two loosest thresholds
no longer resulted in similar performance. The second-loosest marker threshold
now resulted in optimal performance across all parameters and was clearly
distinct from all other parameter combinations.

I observed a relationship between the proportion of cancer cells in a sample and
the accuracy of expression estimation (Figure \@ref(fig:pbulk-acc-v-prop-plt)).
For samples with very small amounts of cancer cells (i.e., low tumor purity),
the estimation accuracy was very low, but rose sharply with increasing tumor
purity. For purities higher than about 0.15 the increase in accuracy slowed and
became close to linear up to maximum purity, indicating a roughly logarithmic
relationship. This behavior was constant across parameter combinations, only the
average accuracy of the near-linear section (i.e., its y-axis intercept)
differed according to the overall average accuracy of the parameter combination.

Using random marker selection resulted in relatively low variation in estimation
accuracy among samples of similar purity. However, there was no point where the
estimation accuracy of a sample was higher than the inherent association between
bulk expression and true cancer expression in a sample, even when excluding
cancer expression. When using Wilcoxon based marker selection, estimation
accuracy was considerably more variable. For lower tumor purities, there were
some samples for which the estimated cancer expression had higher correlation
with true cancer expression than overall bulk expression did, especially when
also excluding the cancer profile from the reference. These, however, were not
enough to lead to a clearly superior estimation accuracy compared to the
inherent relationship between bulk and cancer expression.

The association between cancer expression and overall bulk expression can be
clearly observed on the level of the indiviual sample (Supp. Figure
\@ref(fig:pbulk-sim-diag-1) (C) & Supp. Figure \@ref(fig:pbulk-sim-diag-2) (C)).
For almost all the cell types (save for Plasmablasts and to a lesser extent for
Myeloid cells), there existed strong co-linearity in expression profiles between
each cell type and the others in the sample (Supp. Figure
\@ref(fig:pbulk-sim-diag-1) (D) & Supp. Figure \@ref(fig:pbulk-sim-diag-2) (D)).

```{r pbulk-cexpr-acc-plt, fig.cap = plot_caps$pbulk_cexpr_acc}
include_graphics(plot_paths$pbulk_cexpr_acc)
```

```{r pbulk-acc-v-prop-plt, fig.cap = plot_caps$pbulk_acc_v_prop}
include_graphics(plot_paths$pbulk_acc_v_prop)
```

## Evaluation

### Comparison to BayesPrism {#res-comparison-to-bayesprism}

When comparing deconvPure to BayesPrism on pseudo-bulk and bulk RNA-seq data,
both showed similar behavior with BayesPrism mostly outperforming deconvPure
(Figure \@ref(fig:bp-cexpr-acc-plt)). Only BayesPrism was able to reliably
generate cancer expression estimates with higher accuracy than the inherent
association between the overall bulk expression profile and true cancer
expression. When differences in averages are mentioned, they are again based on
95% CIs. Exact correlations and CIs can be found in Supp. Table
\@ref(tab:bp-cexpr-acc-plt-tab).

On pseudo-bulks derived from distinct tumor samples and using random sets of
genes as markers, there was no variation in performance for each estimation
method. BayesPrism was able to estimate cancer expression in the pseudo-bulks
with very good accuracy, achieving $\rho$ values between 0.95 and 0.98. The
accuracy achieved by deconvPure was not as good, here correlation values only
ranged between 0.79 and 0.84. For the more restrictive Wilcoxon method of marker
selection, there is more variability across the marker sets. deconvPure showed
high estimation accuracy across marker thresholds, while BayesPrism achieved
only medium accuracy at the tightest threshold. BayesPrism also showed a general
trend of better performance at looser marker thresholds, but no differences
besides at the tightest threshold were statistically significant. Also, for
BayesPrism, variability increased for smaller marker gene sets at tighter
thresholds. For the looser thresholds deconvPure had slightly (but not stat.
significantly) better performance than throughout the random marker selection.
BayesPrism on the other hand had worse performance on Wilcoxon markers for the
loosest threshold than on the tightest using random markers, despite the latter
marker set being smaller than the former.

When applied to real-world bulk RNA-seq data, both deconvPure and BayesPrism
showed significantly worse performance on pairs of otherwise equal parameters.
On randomly selected marker genes, both methods only achieved medium to good
correlations. The estimation accuracy of both estimation methods also became
more similar, with no clear differences existing for the two loosest thresholds.
On Wilcoxon based markers, both methods had the lowest estimation accuracies for
this section, achieving only poor to medium correlations between actual and
estimated cancer profiles. The trend of better correlation with looser
thresholds which BayesPrism showed on pseudo-bulks was also present and
deconvPure followed it as well. Lastly, in addition to the generally worse
performance in bulk RNA-seq data, deconvPure also showed a general pattern of
slightly lower performance compared to BayesPrism on this type of data (only
significant at the second-tightest and loosest threshold).

I also observed a general dependence of estimation accuracy on the tumor sample
purity similar to previous sections, but not as clear due to the lower amount of
samples and reduced range in tumor purity (0-70% cancer cells by proportion,
according to scRNA-seq data; Figure \@ref(fig:bp-acc-v-prop-plt)). On
pseudo-bulks, the pattern for deconvPure is also similar to the previous
pseudo-bulk simulation experiments (Section \@ref(res-scrna-seq-pseudo-bulks)):
Low variability on random markers, higher variability for Wilcoxon based
markers, mostly worse than inherent association of bulk and cancer expression.
The one exception is that, on pseudo-bulks derived from real-world samples and
across parameters, deconvPure manged to outperform the inherent association only
on a single pseudo-bulk, and that only by a small margin.

BayesPrism by comparison, was capable of slightly outperforming the inherent
association between bulk and cancer expression (no statistical test performed)
when using randomly selected marker genes (except for some samples using the
tightest threshold). On Wilcoxon based markers, BayesPrism's cancer expression
estimates were generally far below the inherent association, with the only some
exceptions due to the high variability of estimation accuracy.

On the matched real-world bulk data, there was slightly more variability in the
relationship of bulk to cancer expression, but also in the estimation accuracy.
For deconvPure and on estimations using randomly selected markers, the
estimation accuracy was close, but never than the inherent correlation of bulk
and cancer expression. On Wilcoxon based markers, there was little association
between tumor purity and estimation accuracy for all thresholds and a large gap
between estimation accuracy and inherent correlation. BayesPrism on the other
hand was again able to estimate cancer expression with higher accuracy than the
inherent association for most samples when using random marker genes (though
with some variability across thresholds used). This was no longer the case when
using Wilcoxon markers though. As with deconvPure, no improvement over the
inherent association was possible.


```{r bp-cexpr-acc-plt, fig.cap = plot_caps$bp_cexpr_acc}
include_graphics(plot_paths$bp_cexpr_acc)
```

```{r bp-acc-v-prop-plt, fig.cap = plot_caps$bp_acc_v_prop}
include_graphics(plot_paths$bp_acc_v_prop)
```

### Prediction

deconvPure cancer expression estimates could not be used to train models
predicting either the tumor-level or the patient level variable with higher
accuracy than models trained on raw bulk data using the same set of genes.
Again, when differences are mentioned, they are again based on 95% CIs. Exact
correlations and CIs can be found in Supp. Table \@ref(tab:pred-cat-perf-tab)
and Supp. Table \@ref(tab:pred-srv-perf-tab).

When predicting the PAM50 subtype, model accuracy was moderate to good, with the
average model accuracies on bootstrapped test data being relatively close,
ranging from slightly below 0.7 to slightly below 0.8 (Figure
\@ref(fig:pred-cat-perf-plt)). As mentioned, the model trained on estimated
expression from deconvPure achieved a lower accuracy than the model trained on
bulk expression data. It did however outperform the model trained on *full* bulk
data. The model trained on BayesPrism data, was in turn able to achieve a
slightly higher accuracy than the bulk data model for that gene set. Both models
on that gene set (BayesPrism & bulk) also had the highest accuracy of all the
models considered here.

Overall, the model accuracy for predicting PFI from expression data in
conjunction with patient age and tumor status was bad to mediocre, ranging from
around 0.5 to 0.65 (Figure \@ref(fig:pred-srv-perf-plt)). Again, the model
trained with deconvPure estimates was worse than the one trained on matched bulk
data, but the performance of the deconvPure model was only barely better than
pure chance. The model trained with BayesPrism's cancer expression estimates
performed best of all again and outperformed its matched bulk data model. The
model trained with full bulk expression data had the worst performance with the
C-index not clearly different from 0.5, indicating a prediction no better than
chance.

```{r pred-cat-perf-plt, fig.cap = plot_caps$pred_cat_perf}
include_graphics(plot_paths$pred_cat_perf)
```

```{r pred-srv-perf-plt, fig.cap = plot_caps$pred_srv_perf}
include_graphics(plot_paths$pred_srv_perf)
```
